{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "14829a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "/*Copyright (c) 2021 SERVIR-Mekong\n",
    "\n",
    "https://mygeoblog.com/2021/04/12/using-convolutional-neural-networks-part-1/\n",
    "   \n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of the data and associated documentation files, to deal in the data\n",
    "without restriction, including without limitation the rights to use, copy, modify,\n",
    "merge, publish, distribute, sublicense, and/or sell copies, and to permit persons\n",
    "to whom the data is furnished to do so, subject to the following conditions:\n",
    "   \n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "   \n",
    "THE DATA IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "'''\n",
    " \n",
    "import ee\n",
    "import geemap\n",
    "from time import sleep\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    " \n",
    "ee.Initialize()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "48296f13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a53242c0e041bd896c109eb59e59ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the label image collection\n",
    "sparcs = ee.ImageCollection('users/andreanascetti/IEEE/Nice_Labels')\n",
    "\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(sparcs)\n",
    "palette = [\n",
    "  '000000',\n",
    "  'FF5733', #(0)  Urban fabric\n",
    "  'F98A04', #(1)  Industrial, commercial, public, military, private and transport units\n",
    "  'FBDB10', #(2)  Mine, dump and construction sites\n",
    "  'B7E603', #(3)  Artificial non-agricultural vegetated areas\n",
    "  'B6FF45', #(4)  Arable land (annual crops)\n",
    "  '5FB331', #(5)  Permanent crops\n",
    "  '3FAF17', #(6)  Pastures\n",
    "  'FCE5CD', #()complex and mixed...\n",
    "  'C6ECB6', #()orchards at the fringe\n",
    "  '237605', #(7)  Forests\n",
    "  '43B680', #(8)  Herbaceous vegetation associations\n",
    "  '9B621A', #(9)  Open spaces with little or no vegetation\n",
    "  '0691C3', #(10)  Wetlands\n",
    "  '085CB8', #(11)  Water\n",
    "  '000000',\n",
    "]\n",
    "label_params = {'min':0, 'max':15, 'palette':palette}\n",
    "Map.addLayer(sparcs,label_params,\"Labels_Nice\")\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e421c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "period_of_interest = ee.Filter.date('2017-01-01', '2019-12-31')\n",
    "# Map.user_rois.getInfo()\n",
    "Area_Nice = ee.Geometry.Polygon(\n",
    "        [[[6.560201, 43.526958],[6.560201, 44.371294],[7.51888, 44.371294],[7.51888, 43.526958],[6.560201, 43.526958]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e0a89e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the cloud masking function provided by GEE but adapted for use in Python.\n",
    "def maskS2clouds(image):\n",
    "    qa = image.select('QA60')\n",
    "\n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloudBitMask = 1 << 10 # 1024\n",
    "    cirrusBitMask = 1 << 11 # 2048\n",
    "\n",
    "    # Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0)\n",
    "    mask = mask.bitwiseAnd(cirrusBitMask).eq(0)\n",
    "    \n",
    "    helper = image.updateMask(mask).divide(10000)\n",
    "    helper = ee.Image(helper.copyProperties(image, properties=[\"system:time_start\"]))\n",
    "    #ee.Image(helper.copyProperties(image, properties=[\"CLOUD_COVERAGE_PERCENTAGE\"]))\n",
    "\n",
    "    return helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2eca872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produces a kernel of a given sized for sampling in GEE\n",
    "def get_kernel (kernel_size):\n",
    "    eelist = ee.List.repeat(1, kernel_size)\n",
    "    lists = ee.List.repeat(eelist, kernel_size)\n",
    "    kernel = ee.Kernel.fixed(kernel_size, kernel_size, lists)\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d7a27362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['type', 'bands', 'properties'])\n",
      "['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12', 'b1']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edca649b7b9448a88f87d72406973696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define kernel size \n",
    "kernel_size = 256\n",
    "image_kernel = get_kernel(kernel_size) # 256x256 matrix of ones\n",
    " \n",
    "# Specify inputs (Landsat bands) to the model and the response variable.\n",
    "opticalBands = [\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B8A\",\"B11\",\"B12\"]\n",
    " \n",
    "BANDS = opticalBands\n",
    "RESPONSE = ['cloud','shadow','snow','water','land']\n",
    "FEATURES = BANDS + RESPONSE\n",
    "\n",
    "Map = geemap.Map()\n",
    "vis_yellow = {'color': 'f5e105ff'} # yellow\n",
    "vis_green = {'color': '00FF00'} # green\n",
    "vis_blue = {'color': '0000FF'} # blue\n",
    "\n",
    "vis_s2 = {\n",
    "    'bands': ['B4', 'B3', 'B2'],\n",
    "    'min': 0,\n",
    "    'max': 0.3,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for i in range(14,15):#,80,1):\n",
    "     \n",
    "    # get the sparc image\n",
    "    sparcIm = ee.Image(sparcs.toList(100).get(i))#.select(['b1','b2','b3','b4','b5'],RESPONSE) # select([inputBandNames],[newBandNames])\n",
    "    Map.centerObject(sparcIm)\n",
    "    \n",
    "    # generate a negative buffer should be at least 128 pixels x 30 meter\n",
    "    geom = sparcIm.geometry().buffer(-40) # in meter, negative means the geom is contracted\n",
    "    #Map.addLayer(geom,{'color': 'FF0000'},'geom {}'.format(i))\n",
    "    \n",
    "    # create training, testing and validation points, numbers 31 and 17 are used for the random seed.\n",
    "    pointsTrain = ee.FeatureCollection.randomPoints(geom, 7,i) # (region, number of points, seed, maxError)\n",
    "    pointsTest = ee.FeatureCollection.randomPoints(geom, 2,i*31)\n",
    "    pointsVal = ee.FeatureCollection.randomPoints(geom, 1,i*17)\n",
    "    \n",
    "    # get the S2 imagery of the SPARC imagery\n",
    "    dataset = (\n",
    "        ee.ImageCollection('COPERNICUS/S2_SR') \n",
    "        .filterBounds(sparcIm.geometry())\n",
    "        .filter(period_of_interest)\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',10)) \n",
    "        .map(maskS2clouds)\n",
    "        .select(opticalBands)\n",
    "    )\n",
    "    s2Image = dataset.first().clip\n",
    "    Map.addLayer(s2Image)\n",
    "     \n",
    "    # combine the image with the sparc image\n",
    "    image = s2Image.addBands(sparcIm)#.unmask(0,False)\n",
    "        \n",
    "    \n",
    "    # create the neighborhood kernel for sampling\n",
    "    neighborhood = image.neighborhoodToArray(image_kernel) # image\n",
    "    print(neighborhood.getInfo().keys())\n",
    "    print(neighborhood.bandNames().getInfo()) # ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12', 'b1']\n",
    "    #Map.addLayer(neighborhood,{},'neighborhood')\n",
    " \n",
    "    # sample the training, testing and validation \n",
    "    trainingDataTrain = neighborhood.sample(region = pointsTrain,scale= 30,tileScale= 16, geometries= True) # <class 'ee.featurecollection.FeatureCollection'>\n",
    "    trainingDataTest = neighborhood.sample(region = pointsTest, scale= 30,tileScale= 16, geometries= True)\n",
    "    trainingDataVal = neighborhood.sample(region = pointsVal,scale= 30,tileScale= 16, geometries= True)\n",
    "    \n",
    "    #print(trainingDataVal.getInfo().keys())\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Map.addLayer(image,vis_s2,'image {}'.format(i))\n",
    "    \n",
    "    Map.addLayer(sparcIm,label_params,'labels {}'.format(i))\n",
    "    \n",
    "    Map.addLayer(pointsTrain,vis_yellow,'points Train {}'.format(i))\n",
    "    #Map.addLayer(pointsTest,vis_green,'points Test {}'.format(i))\n",
    "    #Map.addLayer(pointsVal,vis_blue,'points Val {}'.format(i))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # export training, test, val patches as TFRecord\n",
    "\n",
    "    \n",
    "'''    trainingTaskTrain = ee.batch.Export.table.toCloudStorage(collection= ee.FeatureCollection(trainingDataTrain),\n",
    "                        description= \"trainpatch\"+str(i),\n",
    "                        fileNamePrefix= folder+ trainFilePrefix,\n",
    "                        bucket= outputBucket,\n",
    "                        fileFormat= 'TFRecord',\n",
    "                        selectors= FEATURES)'''\n",
    "    # execute the tasts\n",
    "#     trainingTaskTrain.start()\n",
    "#     trainingTaskTest.start()\n",
    "#     trainingTaskVal.start()\n",
    "\n",
    "Map     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc35717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow setup.\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    " \n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import losses\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import metrics\n",
    "from tensorflow.python.keras import optimizers\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c52c067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(example_proto):\n",
    "    \"\"\"The parsing function.\n",
    "    Read a serialized example into the structure defined by FEATURES_DICT.\n",
    "    Args:\n",
    "    example_proto: a serialized Example.\n",
    "    Returns:\n",
    "    A dictionary of tensors, keyed by feature name.\n",
    "    \"\"\"\n",
    "    return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
    "\n",
    "def to_tuple(inputs):\n",
    "    \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
    "    Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
    "    Args:\n",
    "    inputs: A dictionary of tensors, keyed by feature name.\n",
    "    Returns:\n",
    "    A tuple of (inputs, outputs).\n",
    "    \"\"\"\n",
    "    inputsList = [inputs.get(key) for key in FEATURES]\n",
    "    stacked = tf.stack(inputsList, axis=0)\n",
    "    # Convert from CHW to HWC\n",
    "    stacked = tf.transpose(stacked, [1, 2, 0])\n",
    "    return stacked[:,:,:len(BANDS)], stacked[:,:,len(BANDS):]\n",
    "\n",
    "def get_dataset(pattern):\n",
    "    \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
    "    Get all the files matching the pattern, parse and convert to tuple.\n",
    "    Args:\n",
    "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
    "    Returns:\n",
    "    A tf.data.Dataset\n",
    "    \"\"\"\n",
    "    glob = tf.io.gfile.glob(pattern)\n",
    "    dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
    "    dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
    "    dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
    "    return dataset\n",
    "\n",
    "def get_training_dataset(glob,eval=True):\n",
    "    \"\"\"Get the preprocessed training dataset\n",
    "    Returns: \n",
    "    A tf.data.Dataset of training data.\n",
    "    \"\"\"\n",
    "    dataset = get_dataset(glob)\n",
    "    if eval:\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "    else:\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    return dataset\n",
    "\n",
    "def conv_block(input_tensor, num_filters):\n",
    "    encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
    "    encoder = layers.BatchNormalization()(encoder)\n",
    "    encoder = layers.Activation('relu')(encoder)\n",
    "    encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
    "    encoder = layers.BatchNormalization()(encoder)\n",
    "    encoder = layers.Activation('relu')(encoder)\n",
    "    return encoder\n",
    "\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "    encoder = conv_block(input_tensor, num_filters)\n",
    "    encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
    "    return encoder_pool, encoder\n",
    " \n",
    "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
    "    decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
    "    decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    return decoder\n",
    " \n",
    "def get_model():\n",
    "    n = 4\n",
    "    inputs = layers.Input(shape=[None, None, len(BANDS)]) \n",
    "    encoder0_pool, encoder0 = encoder_block(inputs, n) \n",
    "    encoder1_pool, encoder1 = encoder_block(encoder0_pool, n*2) \n",
    "    encoder2_pool, encoder2 = encoder_block(encoder1_pool, n*4)\n",
    "    encoder3_pool, encoder3 = encoder_block(encoder2_pool, n*8)\n",
    "    encoder4_pool, encoder4 = encoder_block(encoder3_pool, n*16)\n",
    "    center = conv_block(encoder4_pool, n*32) # center\n",
    "    decoder4 = decoder_block(center, encoder4, n*16) \n",
    "    decoder3 = decoder_block(decoder4, encoder3, n*8) \n",
    "    decoder2 = decoder_block(decoder3, encoder2, n*4)\n",
    "    decoder1 = decoder_block(decoder2, encoder1, n*2)\n",
    "    decoder0 = decoder_block(decoder1, encoder0, n)\n",
    "    outputs = layers.Conv2D(5, (1, 1), activation='softmax')(decoder0)\n",
    " \n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    " \n",
    "    print(model.summary())\n",
    " \n",
    "    model.compile(\n",
    "        optimizer = 'ADAM', \n",
    "        loss = losses.categorical_crossentropy,\n",
    "        metrics = [metrics.categorical_accuracy])\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e530ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
    "COLUMNS = [tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES]\n",
    "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
    " \n",
    "# Specify model training parameters.\n",
    "TRAIN_SIZE = 6000 # train size is 80*100*0.7\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 16\n",
    "BUFFER_SIZE = 4000 \n",
    "   \n",
    "# location of the gcp bucket\n",
    "data_path = \"/path/to/data/\"\n",
    " \n",
    "# import the training, testing and validation records\n",
    "training_files = data_path + '/training/train*'\n",
    "testing_files = data_path + '/testing/test*'\n",
    "validation_files = data_path + '/validation/val*' \n",
    "\n",
    "training_ds = get_training_dataset(training_files)\n",
    "testing_ds = get_training_dataset(testing_files)  \n",
    "validation_ds = get_training_dataset(validation_files,False)\n",
    "\n",
    "model = get_model()\n",
    " \n",
    "model.fit(\n",
    "   x = training_ds, \n",
    "   epochs = EPOCHS, \n",
    "   steps_per_epoch =int(TRAIN_SIZE / BATCH_SIZE), \n",
    "   validation_data = testing_ds,\n",
    "   validation_steps = 100)\n",
    " \n",
    "print(model.evaluate(x=validation_ds))\n",
    " \n",
    "# save model\n",
    "MODEL_DIR = '/path/to/save/qamodel/'\n",
    "tf.saved_model.save(model, MODEL_DIR)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "gee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
